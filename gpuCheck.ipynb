{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3936269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a69b5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de4d38fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e132ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla K80'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2216360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可用的 GPU 數量： 2\n",
      "計算結果： tensor([[-0.7590, -0.4708,  0.2896, -0.6696, -0.2129],\n",
      "        [-0.5638, -0.2819,  0.4481, -0.5891, -0.0515],\n",
      "        [-0.1075, -0.0949,  0.1688, -0.4538, -0.4283],\n",
      "        [-0.3708, -0.3003, -0.0473,  0.2497, -0.5544],\n",
      "        [-0.5383,  0.2033, -0.6988, -0.7751, -0.0226],\n",
      "        [-0.2270,  0.2444, -0.3936, -0.0570, -0.6307],\n",
      "        [ 0.3330,  0.4805, -0.3101, -0.0993, -0.5016],\n",
      "        [-1.4283, -0.2140,  0.6914, -0.8494, -0.1189],\n",
      "        [ 0.0459,  0.1797, -0.2149, -0.1494, -0.2397],\n",
      "        [ 0.7235,  0.1472,  0.2309,  0.0468,  0.0087],\n",
      "        [ 0.4711, -1.7408, -0.4935,  1.0903, -0.4885],\n",
      "        [-0.3255,  1.1619, -0.3112,  1.0745, -1.5568],\n",
      "        [ 0.5323, -0.2378, -0.0841, -0.0148,  0.3711],\n",
      "        [-1.1238,  1.6141, -0.2578,  0.7390, -1.6973],\n",
      "        [-1.0016, -0.2256,  0.3355,  0.1234, -0.3571],\n",
      "        [ 0.5881,  0.0259,  0.5200, -0.2217, -0.0382],\n",
      "        [ 0.1251,  1.0232,  0.1356, -0.9037,  0.3627],\n",
      "        [ 0.2211, -0.3341,  0.1317, -0.4378,  0.2955],\n",
      "        [ 0.8334,  0.8534, -0.3886, -1.3590, -0.0042],\n",
      "        [-0.2449, -0.1368, -0.7892,  0.8968, -1.0380]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 確認可用的 GPU 數量\n",
    "device_count = torch.cuda.device_count()\n",
    "print(\"可用的 GPU 數量：\", device_count)\n",
    "\n",
    "# 檢查是否有至少兩個可用的 GPU\n",
    "if device_count < 2:\n",
    "    print(\"系統上的 GPU 數量不足，無法在兩個 GPU 上運行程式碼。\")\n",
    "    exit()\n",
    "\n",
    "# 定義模型\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# 建立模型\n",
    "model = MyModel()\n",
    "\n",
    "# 指定兩個 GPU 的 device IDs\n",
    "device1 = torch.device(\"cuda:0\")\n",
    "device2 = torch.device(\"cuda:1\")\n",
    "\n",
    "# 將模型移動到第一個 GPU\n",
    "model.to(device1)\n",
    "\n",
    "# 在第一個 GPU 上創建輸入張量\n",
    "input_tensor1 = torch.randn(10, 10).to(device1)\n",
    "\n",
    "# 建立模型的複本，移動到第二個 GPU\n",
    "model2 = MyModel()\n",
    "model2.to(device2)\n",
    "\n",
    "# 在第二個 GPU 上創建輸入張量\n",
    "input_tensor2 = torch.randn(10, 10).to(device2)\n",
    "\n",
    "# 在兩個 GPU 上執行計算\n",
    "with torch.cuda.device(device1):\n",
    "    output1 = model(input_tensor1)\n",
    "\n",
    "with torch.cuda.device(device2):\n",
    "    output2 = model2(input_tensor2)\n",
    "\n",
    "# 將結果移回 CPU 或合併結果\n",
    "output1 = output1.to(\"cpu\")\n",
    "output2 = output2.to(\"cpu\")\n",
    "merged_output = torch.cat([output1, output2], dim=0)\n",
    "\n",
    "print(\"計算結果：\", merged_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ea0f325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可用的 GPU 數量： 2\n",
      "第一個 GPU 上的計算結果： tensor([[-0.1459, -0.1534,  0.7309,  0.3647,  0.9250],\n",
      "        [-0.1357, -0.2351,  0.6441,  0.0348, -0.0303],\n",
      "        [ 0.5310,  0.7900,  1.0667,  0.9989,  0.5784],\n",
      "        [-0.1958, -0.3272, -0.3495, -0.3941, -0.0589],\n",
      "        [ 0.3061, -0.0690,  0.4494,  0.2026,  0.7814],\n",
      "        [-0.1388,  0.3680,  0.0729,  0.0380,  0.6804],\n",
      "        [-0.5484, -0.1583,  0.1468, -1.3566, -0.0049],\n",
      "        [ 0.6335,  0.3845,  0.3377, -0.2140, -0.0589],\n",
      "        [-0.4645, -0.0454,  0.6996, -0.0893,  0.7411],\n",
      "        [-0.0895,  0.2486, -0.4159,  0.2451,  0.9898]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "第二個 GPU 上的計算結果： tensor([[ 1.4271e+00,  2.3908e-01, -1.5710e-01,  5.8725e-02,  8.8830e-01],\n",
      "        [-7.3465e-01, -3.5177e-01,  4.0889e-01, -8.3700e-02, -5.5197e-01],\n",
      "        [ 6.1514e-01, -1.1656e+00,  2.3096e-01,  3.7953e-01,  8.0007e-02],\n",
      "        [ 5.8639e-03, -8.2411e-01, -3.1226e-01,  2.1048e+00, -3.4119e-01],\n",
      "        [ 2.5821e-01, -8.9238e-01, -1.0338e-01,  6.5184e-01,  3.4266e-01],\n",
      "        [ 8.0010e-01,  4.3776e-01, -5.1539e-01,  8.6103e-01,  1.3133e-01],\n",
      "        [-8.0770e-01, -1.2368e-01,  2.4153e-01, -9.4795e-01, -5.0888e-01],\n",
      "        [-4.2820e-01, -6.2997e-01, -9.1096e-01, -3.8815e-01, -6.4431e-02],\n",
      "        [ 4.2310e-02,  5.2127e-01,  5.9938e-02,  6.5912e-01, -5.5977e-01],\n",
      "        [-4.3108e-01, -1.1414e+00,  8.9282e-04, -3.6139e-01, -7.0633e-01]],\n",
      "       device='cuda:1', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 確認可用的 GPU 數量\n",
    "device_count = torch.cuda.device_count()\n",
    "print(\"可用的 GPU 數量：\", device_count)\n",
    "\n",
    "# 檢查是否有至少兩個可用的 GPU\n",
    "if device_count < 2:\n",
    "    print(\"系統上的 GPU 數量不足，無法在兩個 GPU 上運行程式碼。\")\n",
    "    exit()\n",
    "\n",
    "# 指定兩個 GPU 的 device IDs\n",
    "device1 = torch.device(\"cuda:0\")\n",
    "device2 = torch.device(\"cuda:1\")\n",
    "\n",
    "# 在第一個 GPU 上進行運算\n",
    "with torch.cuda.device(device1):\n",
    "    # 建立模型\n",
    "    model1 = MyModel().to(device1)\n",
    "    input_tensor1 = torch.randn(10, 10).to(device1)\n",
    "    output1 = model1(input_tensor1)\n",
    "    print(\"第一個 GPU 上的計算結果：\", output1)\n",
    "\n",
    "# 在第二個 GPU 上進行運算\n",
    "with torch.cuda.device(device2):\n",
    "    # 建立模型\n",
    "    model2 = MyModel().to(device2)\n",
    "    input_tensor2 = torch.randn(10, 10).to(device2)\n",
    "    output2 = model2(input_tensor2)\n",
    "    print(\"第二個 GPU 上的計算結果：\", output2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
